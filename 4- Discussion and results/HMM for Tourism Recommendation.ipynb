{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM for Tourism Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to open the csv.\n",
    "\n",
    "We drop a certain number of columns (often geographic data because not necessary for the analysis). You can also drop rows where data is missing (especially when the nationality is not filled in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ouverture(nom):\n",
    "    df = pd.read_csv(nom, sep = \",\" )\n",
    "    df = df.drop(columns = ['Unnamed: 0', 'gid_0', 'name_0', 'gid_1','name_1','gid_2', 'name_2', 'gid_3' ,'name_3', 'gid_4', 'name_4', 'gid_5', 'name_5', 'idplace'])\n",
    "    df['date_review'] = df['date_review'].replace('0000-00-00', np.nan)\n",
    "    df = df.dropna()\n",
    "    df['date_review'] = pd.to_datetime(df['date_review'], format = '%Y-%m-%d')\n",
    "    df = df[df.country != '-']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>id</th>\n",
       "      <th>idauteur</th>\n",
       "      <th>date_review</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'Insoumise, France</td>\n",
       "      <td>48,835045</td>\n",
       "      <td>2,28915</td>\n",
       "      <td>328246480</td>\n",
       "      <td>AEC731BAB7B8CCA02944C293198E3FC6</td>\n",
       "      <td>2015-11-21</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinq Mondes Paris</td>\n",
       "      <td>48,871681</td>\n",
       "      <td>2,32899</td>\n",
       "      <td>331590265</td>\n",
       "      <td>26ABC72A68434467E4D20CEC4F1B3DC3</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'Envie, France</td>\n",
       "      <td>48,83414</td>\n",
       "      <td>2,317883</td>\n",
       "      <td>262837346</td>\n",
       "      <td>36B0E60FD21BFE2377C526209C3FF4D5</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Ciel de Paris, France</td>\n",
       "      <td>48,84219</td>\n",
       "      <td>2,32198</td>\n",
       "      <td>266833774</td>\n",
       "      <td>72C94635808B0207A5A664DD646F3744</td>\n",
       "      <td>2015-04-20</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe Les Deux Magots, France</td>\n",
       "      <td>48,853973</td>\n",
       "      <td>2,333158</td>\n",
       "      <td>304112023</td>\n",
       "      <td>F007B2D8152512B20BB4EB3E7C5ACA2C</td>\n",
       "      <td>2015-08-27</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nom   latitude longitude         id  \\\n",
       "0           L'Insoumise, France  48,835045   2,28915  328246480   \n",
       "1             Cinq Mondes Paris  48,871681   2,32899  331590265   \n",
       "2               L'Envie, France   48,83414  2,317883  262837346   \n",
       "3      Le Ciel de Paris, France   48,84219   2,32198  266833774   \n",
       "4  Cafe Les Deux Magots, France  48,853973  2,333158  304112023   \n",
       "\n",
       "                           idauteur date_review country  \n",
       "0  AEC731BAB7B8CCA02944C293198E3FC6  2015-11-21   Italy  \n",
       "1  26ABC72A68434467E4D20CEC4F1B3DC3  2015-12-09  France  \n",
       "2  36B0E60FD21BFE2377C526209C3FF4D5  2015-03-31  France  \n",
       "3  72C94635808B0207A5A664DD646F3744  2015-04-20  France  \n",
       "4  F007B2D8152512B20BB4EB3E7C5ACA2C  2015-08-27  Brazil  "
      ]
     },
     "execution_count": 1373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ouverture('sample_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de lieux différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9420"
      ]
     },
     "execution_count": 1374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(df['nom'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de reviews totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56264"
      ]
     },
     "execution_count": 1375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the year for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_annee(annee, df):\n",
    "    df = df[(df['date_review'].dt.year > annee - 1) & (df['date_review'].dt.year < annee + 1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = selection_annee(2015, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of reviews in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56264"
      ]
     },
     "execution_count": 1378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the number of places to be processed (the first top k)\n",
    "\n",
    "To do so, we group the name of the place, to which we apply the count function of the unique number of reviews (represented by the id column). We then sort the result to get the top of the represented places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(k, df):\n",
    "    top_k = df.groupby('nom').count()['id'].sort_values(ascending = False)[0:k]\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1380,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_k = top_k(10, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nom\n",
       "Musée du Louvre                          1549\n",
       "Eiffel Tower                             1516\n",
       "Cathédrale Notre-Dame de Paris            749\n",
       "Arc de Triomphe                           711\n",
       "Jardin du Luxembourg                      589\n",
       "La Seine                                  478\n",
       "Musée d'Orsay                             413\n",
       "Basilique du Sacré-Cœur de Montmartre     367\n",
       "Champs-Élysées                            348\n",
       "Opéra Garnier                             333\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 1381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now reduce the DataFrame to the top k of places "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_keep(df, top_k):\n",
    "    keep = pd.DataFrame(columns = df.columns)\n",
    "    for places in top_k.index:\n",
    "        keep = keep.append(df[df['nom'] == places])\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = to_keep(df2, tp_k).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the percentage that the top_K represents in relation to the totality of the reviews of the chosen year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12535546708374803"
      ]
     },
     "execution_count": 1384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3.index)/len(df2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to create the sequences, for the sake of clarity and processing, we're going to assign a number to each location. Then reduce it to 1 digit via the ascii column.\n",
    "\n",
    "We can later modify the Alergia algorithm so that it can take into account the double digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nom</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>id</th>\n",
       "      <th>idauteur</th>\n",
       "      <th>date_review</th>\n",
       "      <th>country</th>\n",
       "      <th>Group_ID</th>\n",
       "      <th>ascii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Musée du Louvre</td>\n",
       "      <td>48,861</td>\n",
       "      <td>2,335833</td>\n",
       "      <td>311501513</td>\n",
       "      <td>4B018C46529B92190134DEBD3D429BCD</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>Italy</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>Musée du Louvre</td>\n",
       "      <td>48,861</td>\n",
       "      <td>2,335833</td>\n",
       "      <td>288015394</td>\n",
       "      <td>294FB3D2C00277C2A2F563F2D4DA7A55</td>\n",
       "      <td>2015-07-11</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117</td>\n",
       "      <td>Musée du Louvre</td>\n",
       "      <td>48,861</td>\n",
       "      <td>2,335833</td>\n",
       "      <td>316627370</td>\n",
       "      <td>39AE30708C84823D0A6DEFB86D7D2370</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>Musée du Louvre</td>\n",
       "      <td>48,861</td>\n",
       "      <td>2,335833</td>\n",
       "      <td>277869091</td>\n",
       "      <td>2D508690DD4E5281BF88B235E1121A2C</td>\n",
       "      <td>2015-06-04</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>Musée du Louvre</td>\n",
       "      <td>48,861</td>\n",
       "      <td>2,335833</td>\n",
       "      <td>249606817</td>\n",
       "      <td>F6883072C58471A6A04D7FBFB9608DA2</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              nom latitude longitude         id  \\\n",
       "0      8  Musée du Louvre   48,861  2,335833  311501513   \n",
       "1     76  Musée du Louvre   48,861  2,335833  288015394   \n",
       "2    117  Musée du Louvre   48,861  2,335833  316627370   \n",
       "3    143  Musée du Louvre   48,861  2,335833  277869091   \n",
       "4    152  Musée du Louvre   48,861  2,335833  249606817   \n",
       "\n",
       "                           idauteur date_review    country  Group_ID ascii  \n",
       "0  4B018C46529B92190134DEBD3D429BCD  2015-09-18      Italy         8     8  \n",
       "1  294FB3D2C00277C2A2F563F2D4DA7A55  2015-07-11    Ireland         8     8  \n",
       "2  39AE30708C84823D0A6DEFB86D7D2370  2015-10-06  Argentina         8     8  \n",
       "3  2D508690DD4E5281BF88B235E1121A2C  2015-06-04     Turkey         8     8  \n",
       "4  F6883072C58471A6A04D7FBFB9608DA2  2015-01-16     Brazil         8     8  "
      ]
     },
     "execution_count": 1385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Group_ID'] = df3.groupby('nom').grouper.group_info[0]\n",
    "df3['ascii'] = df3.Group_ID.apply(lambda x: chr(x+48))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6424"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(df3.idauteur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asciiToName(df):\n",
    "    testdata = df[['ascii', 'nom']].values\n",
    "    return dict(list(set(tuple(x) for x in testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = asciiToName(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite avoir la correspondance des digit des séquences aux lieux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7': \"Musée d'Orsay\",\n",
       " '5': 'Jardin du Luxembourg',\n",
       " '0': 'Arc de Triomphe',\n",
       " '2': 'Cathédrale Notre-Dame de Paris',\n",
       " '3': 'Champs-Élysées',\n",
       " '9': 'Opéra Garnier',\n",
       " '4': 'Eiffel Tower',\n",
       " '6': 'La Seine',\n",
       " '8': 'Musée du Louvre',\n",
       " '1': 'Basilique du Sacré-Cœur de Montmartre'}"
      ]
     },
     "execution_count": 1389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now move on to the creation of sequences for each user. The particularity is that we are going to separate the sequences according to the number of days between 2 photos.\n",
    "\n",
    "We start by grouping the places in chronological order according to the author's id. In other words, we are going to put in a list the reviewed places with their respective date of publication for each user. \n",
    "Then, we will compare the time delta between the review i and the i + 1. If it is less than or equal to the desired parameter, we add the element to the sequence *a* . Otherwise, we end the sequence, and we separate the two reviews in 2 distinct sequences *a* and *b*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequencesv2(df, threshold_days):\n",
    "    df2 = df.sort_values('date_review', ascending = True).groupby('idauteur').apply(lambda x: x[['ascii','date_review']].values.tolist()).reset_index(name='col')\n",
    "    \n",
    "    df2['len'] = df2['col'].map(len)\n",
    "    df2 = df2[df2['len'] >= 2] \n",
    "\n",
    "    sequences_finales = [] #used to split patterns according to the threshold of days we want between 2 days\n",
    "            \n",
    "    for element in df2['col']:\n",
    "        sublist = ''\n",
    "        sublist2 = ''\n",
    "        for i in range(1, len(element)):\n",
    "            \n",
    "            diff = abs(element[i-1][1] - element[i][1]).days\n",
    "            \n",
    "            if(diff <= threshold_days): #IF THE PICTURE AND THE PREVIOUS ONE HAVE LESS THAN X DAYS \n",
    "                \n",
    "                if(i == 1): #if at the beginning of the sequence\n",
    "                    sublist += element[i-1][0] #we add the first element of the sequence\n",
    "        \n",
    "                sublist += element[i][0] #if not, we add the current one to the sublist\n",
    "                   \n",
    "            else: #IF THERE IS MORE THAN X DAYS :\n",
    "                \n",
    "                if(len(sublist) != 0): #if we stop a existing sequence, we add it\n",
    "                    sequences_finales.append(sublist)  \n",
    "                    sublist = ''\n",
    "                \n",
    "                if(i == 1): #if at the beginning of the sequence\n",
    "                    sublist += element[i-1][0] #we add the first one\n",
    "                    sequences_finales.append(sublist)  #then we cut the sub-sequence\n",
    "                    sublist ='' #and we reset the sub-sequence\n",
    "                    \n",
    "                sublist += element[i][0] #if not, we create another sub-sequence\n",
    "                \n",
    "                    \n",
    "        if(len(sublist) != 0): #at the end, we add the subsequence\n",
    "            sequences_finales.append(sublist)\n",
    "                    \n",
    "    lieux = df['nom'].unique() \n",
    "    \n",
    "    return lieux, sequences_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "lieux, sequences = create_sequencesv2(df3, 7) #utiliser 7 pour être en accord avec l'état de l'art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we keep only the sequences of size > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutSeq(sequences):\n",
    "    seq2j = []\n",
    "    for s in sequences:\n",
    "        if len(s) >= 2:\n",
    "            seq2j.append(s)\n",
    "    return seq2j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2j = cutSeq(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageLen(lst):\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average size of tourist sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0862533692722374"
      ]
     },
     "execution_count": 1395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averageLen(seq2j) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 1396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq2j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "for s in seq2j:\n",
    "    if(len(s) > maxx):\n",
    "        maxx = len(s)\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 5 sequences returned by the algorithm. We don't have access to any user data, only to sequences of items (each symbol represents a place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['96', '10', '72', '19', '806']"
      ]
     },
     "execution_count": 1398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2j[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the sequences, it starts from 0 to len. \n",
    "#### All parameters are therefore the desired position - 1 (0 for 1st element, 1 for 2nd, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeqAtPosition(sequences, element, position):\n",
    "    result = []\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq)):\n",
    "            if(i == position):\n",
    "                if(seq[i] == element):\n",
    "                    result.append(seq)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourEiffel1 = getSeqAtPosition(seq2j[:1000], str(2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourEiffel2 = getSeqAtPosition(seq2j[:1000], str(2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourEiffel3 = getSeqAtPosition(seq2j[:1000], str(2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "notreDame1 = getSeqAtPosition(seq2j[:1000], str(1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "notreDame2 = getSeqAtPosition(seq2j[:1000], str(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "notreDame3 = getSeqAtPosition(seq2j[:1000], str(1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "laSeine1 = getSeqAtPosition(seq2j[:1000], str(4), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "laSeine2 = getSeqAtPosition(seq2j[:1000], str(4), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "laSeine3 = getSeqAtPosition(seq2j[:1000], str(4), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvre1 = getSeqAtPosition(seq2j[:1000], str(5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvre2 = getSeqAtPosition(seq2j[:1000], str(5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvre3 = getSeqAtPosition(seq2j[:1000], str(5), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['56', '50', '52', '580', '58']\n",
      "['85', '65', '1583', '65', '75']\n",
      "['465', '605']\n"
     ]
    }
   ],
   "source": [
    "print(louvre1[:5])\n",
    "print(louvre2[:5])\n",
    "print(louvre3[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbaPredecessor(sequences, element, position):\n",
    "    dic = dict.fromkeys(range(len(tp_k)), 0)\n",
    "    for seq in sequences:\n",
    "        key = int(seq[position - 1])\n",
    "        dic[key] += 1\n",
    "    res = {key: dic[key] / len(sequences) \n",
    "                        for key in dic.keys()}\n",
    "    values = sum(dic.values())\n",
    "    res = {key : dic[key] / values for key in dic.keys()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbaSuccessor(sequences, element, position):\n",
    "    dic = dict.fromkeys(range(len(tp_k)), 0)\n",
    "    for seq in sequences:\n",
    "        if(len(seq) > position +1):\n",
    "            key = int(seq[position + 1])\n",
    "            dic[key] += 1\n",
    "    res = {key: dic[key] / len(sequences) \n",
    "                        for key in dic.keys()}\n",
    "    #values = sum(dic.values())\n",
    "    #res = {key : dic[key] / values for key in dic.keys()}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.05,\n",
       " 1: 0.125,\n",
       " 2: 0.1,\n",
       " 3: 0.0,\n",
       " 4: 0.15,\n",
       " 5: 0.0,\n",
       " 6: 0.15,\n",
       " 7: 0.025,\n",
       " 8: 0.35,\n",
       " 9: 0.05}"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProbaPredecessor(louvre2, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.15789473684210525,\n",
       " 1: 0.02631578947368421,\n",
       " 2: 0.07894736842105263,\n",
       " 3: 0.10526315789473684,\n",
       " 4: 0.07894736842105263,\n",
       " 5: 0.0,\n",
       " 6: 0.10526315789473684,\n",
       " 7: 0.0,\n",
       " 8: 0.3684210526315789,\n",
       " 9: 0.07894736842105263}"
      ]
     },
     "execution_count": 1416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProbaSuccessor(louvre1, 5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 0.0,\n",
       " 2: 0.05,\n",
       " 3: 0.0,\n",
       " 4: 0.0,\n",
       " 5: 0.0,\n",
       " 6: 0.0,\n",
       " 7: 0.0,\n",
       " 8: 0.05,\n",
       " 9: 0.0}"
      ]
     },
     "execution_count": 1417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProbaSuccessor(louvre2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0,\n",
       " 1: 0.0,\n",
       " 2: 0.0,\n",
       " 3: 0.0,\n",
       " 4: 0.0,\n",
       " 5: 0.0,\n",
       " 6: 0.0,\n",
       " 7: 0.0,\n",
       " 8: 0.0,\n",
       " 9: 0.0}"
      ]
     },
     "execution_count": 1418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getProbaSuccessor(louvre3, 5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the FPTA \n",
    "\n",
    "In order to be able to make our predictions, we first need to create our prefix tree, representing all the possible sequences read by the tree. \n",
    "\n",
    "We start by creating the *TrieNode* class. It represents a node of our tree. It takes as attribute:\n",
    "- a string of characters 'text', which represents the label of each node.\n",
    "- an 'is_word' boolean initialized to False. It becomes True if it has no children (i.e. if the word is finished).\n",
    "- a list of children, to which we initialize for all nodes the first element representing the number of words ending at this node (completes the boolean presented above)\n",
    "- an integer 'state', which represents the id of the node. It is unique for each node of the tree.\n",
    "- an 'is_displayed' boolean initialized to False. It is used when displaying the tree, when there are loops so that it is displayed only once.\n",
    "- a list of precedents, which grows as you go. All the precedents of each node are added to it. For the root node, we consider that its predecessor is itself.\n",
    "\n",
    "For the *PrefixTree* class, which represents the tree as such, we have:\n",
    "- a *TrieNode* which represents the root node.\n",
    "- class functions that we will detail below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class functions of the *PrefixTree*.\n",
    "\n",
    "#### Insert function:\n",
    "It allows us to insert a word (taken as a parameter), starting from a certain node (current parameter). To do so, we enumerate the word (each character is taken one by one with its corresponding index), then, if the character is not present in the list of children, we will create a node and then increment the indices. If there already exists a child node with the same character, we increment its frequency by 1. When the word is finished, we pass the boolean to True, and we increment the word counter by 1. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Trie_example.svg/1200px-Trie_example.svg.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    _COUNTER_NODE = 1\n",
    "    def __init__(self, text = \"λ\"):\n",
    "        self.text = text\n",
    "        self.is_word = False\n",
    "        self.children = list()\n",
    "        self.children.append(['#', 0, self]) #1st element:SYMB 2nd element:FREQUENCY 3rd element:CHILDREN \n",
    "        self.state = TrieNode._COUNTER_NODE\n",
    "        TrieNode._COUNTER_NODE += 1\n",
    "        self.previous = []\n",
    "\n",
    "    def get_frequency(self): # Not counting the number of times a word ends \n",
    "        freq = 0\n",
    "        for child in self.children[1:]:\n",
    "            freq += child[1]\n",
    "        return freq\n",
    "    \n",
    "    def get_frequency2(self):\n",
    "        freq = 0\n",
    "        for child in self.children:\n",
    "            freq += child[1]\n",
    "        return freq\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'symb:{} state:{} -> children:{}'.format(self.text, self.state, self.children)\n",
    "\n",
    "class PrefixTree:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "        self.matrice_transition = pd.DataFrame()\n",
    "        self.matrice_emission = pd.DataFrame()\n",
    "\n",
    "    def insert(self, word, current = None):\n",
    "        '''\n",
    "        Creates a given word in the trie\n",
    "        '''\n",
    "        if not current: \n",
    "            current = self.root\n",
    "            pre = self.root\n",
    "            \n",
    "        for i, char in enumerate(word):\n",
    "            \n",
    "            if char not in [x[0] for x in current.children]:\n",
    "                prefix = word[0:i+1]\n",
    "                current.children.append([char, 1, TrieNode(prefix)])\n",
    "                \n",
    "                if pre not in current.previous:\n",
    "                    current.previous.append(pre)\n",
    "                    \n",
    "                pre = current\n",
    "                current = current.children[-1][2]\n",
    "\n",
    "            else:\n",
    "                for child in current.children:\n",
    "                    if child[0] == char:\n",
    "                        child[1] += 1\n",
    "                        \n",
    "                        if pre not in current.previous:\n",
    "                            current.previous.append(pre)\n",
    "                            \n",
    "                        pre = current\n",
    "                        current = child[2]\n",
    "\n",
    "        current.is_word = True   \n",
    "        current.children[0][1] += 1\n",
    "        \n",
    "    def starts_with(self, prefix, current = None):\n",
    "        '''\n",
    "        Returns a list of all words beginning with the given prefix, or\n",
    "        an empty list if no words begin with that prefix.\n",
    "        '''\n",
    "        words = list()\n",
    "        if not current:\n",
    "            current = self.root\n",
    "        for char in prefix:\n",
    "            if char not in [x[0] for x in current.children]:\n",
    "                return list()\n",
    "            for child in current.children:\n",
    "                  if child[0] == char:\n",
    "                    current = child[2]\n",
    "        self.__child_words_for(current, words)\n",
    "        return words\n",
    "    \n",
    "    def __child_words_for(self, node, words):\n",
    "        '''\n",
    "        Private helper function. Cycles through all children\n",
    "        of node recursively, adding them to words if they\n",
    "        constitute whole words (as opposed to merely prefixes).\n",
    "        '''\n",
    "        if node.is_word:\n",
    "            words.append(node.text)\n",
    "        for child in node.children[1:]:\n",
    "            self.__child_words_for(child[2], words)\n",
    "    \n",
    "    def size(self, current = None, visited = None):\n",
    "        '''\n",
    "        Returns the size of this prefix tree, defined\n",
    "        as the total number of nodes in the tree.\n",
    "        '''\n",
    "        # By default, get the size of the whole trie, starting at the root\n",
    "        if not current:\n",
    "            current = self.root\n",
    "        \n",
    "        if not visited:\n",
    "            visited = []\n",
    "            visited.append(current)\n",
    "            \n",
    "        count = 1\n",
    "        \n",
    "        for child in current.children[1:]:\n",
    "            if(child[2] not in visited):\n",
    "                visited.append(child[2])\n",
    "                count += self.size(child[2], visited)\n",
    "                \n",
    "        return count\n",
    "\n",
    "    def leaf(self, current = None, visited = None):\n",
    "        if not current: \n",
    "            current = self.root\n",
    "            \n",
    "        if not visited:\n",
    "            visited = []\n",
    "            \n",
    "        count = 0\n",
    "        tmp = 0\n",
    "        \n",
    "        self.__child_words_for(current, count)        \n",
    "        return count\n",
    "    \n",
    "    def __leaves_for(self, current, count, visited):\n",
    "        if current.is_word == True:\n",
    "            count += 1\n",
    "        for child in current.children[1:]:\n",
    "            if(child[2] not in visited):\n",
    "                visited.append(child[2])\n",
    "                self.__leaves_for(child[2], count, visited)\n",
    "    \n",
    "    def transform2proba(self, current = None):\n",
    "        if not current:\n",
    "            current = self.root\n",
    "            \n",
    "        freq = current.get_frequency2()\n",
    "        for child in current.children:\n",
    "            if(isinstance(child[1], int) == False):\n",
    "                return 0\n",
    "            else: \n",
    "                child[1] = child[1]/freq\n",
    "                if child[2].state != current.state:\n",
    "                    current = child[2]    \n",
    "                    self.transform2proba(current)\n",
    "    \n",
    "    def group_transition(self, node):\n",
    "        result = []\n",
    "        for child in node.children:\n",
    "            list_child = [x for x in node.children if x[2].state == child[2].state]\n",
    "            if list_child not in result:\n",
    "                result.append(list_child)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def transform_to_HMMT(self, current = None, visited = None):\n",
    "        if not current:\n",
    "            current = self.root\n",
    "\n",
    "        if not visited:\n",
    "            visited = []\n",
    "            visited.append(current)\n",
    "\n",
    "        freq = current.get_frequency2()\n",
    "\n",
    "        for child in current.children:\n",
    "            if(len(child) <= 3):\n",
    "                trans = self.group_transition(current)\n",
    "\n",
    "                for sub in trans:\n",
    "                    sum_ = 0\n",
    "                    for node in sub:\n",
    "                        sum_ += node[1]\n",
    "                    for node in sub:\n",
    "                        node[1] /= sum_\n",
    "                        node.append(sum_)              \n",
    "\n",
    "        for child in current.children[1:]:\n",
    "            if child[2] not in visited:  \n",
    "                visited.append(current) \n",
    "                self.transform_to_HMMT(child[2], visited)   \n",
    "                \n",
    "    def create_matrix_transition(self, current = None, visited = None):\n",
    "        if not current:\n",
    "            current = self.root\n",
    "        \n",
    "        if not visited:\n",
    "            visited = []   \n",
    "            \n",
    "        for i in range(len(current.children)):\n",
    "            listt = self.group_transition(current)\n",
    "            for c in listt:\n",
    "                self.matrice_transition.loc[current.text, c[0][2].text] = round(c[0][3], 2)\n",
    "            visited.append(current)\n",
    "                \n",
    "        for i in range(len(current.children)):\n",
    "            if(current.children[i][2] not in visited):\n",
    "                self.create_matrix_transition(current.children[i][2], visited) \n",
    "                \n",
    "        self.matrice_transition = self.matrice_transition.fillna(0).astype('float')\n",
    "        #self.matrice_transition = self.matrice_transition.to_numpy(dtype = 'float')\n",
    "        \n",
    "    def create_matrix_emission(self, current = None, visited = None):\n",
    "        if not current:\n",
    "            current = self.root\n",
    "        \n",
    "        if not visited:\n",
    "            visited = []\n",
    "            \n",
    "        for i in range(len(current.children)):\n",
    "            self.matrice_emission.loc[current.text, current.children[i][0]] = round(current.children[i][1], 2)\n",
    "            visited.append(current)\n",
    "        \n",
    "        for i in range(len(current.children)):\n",
    "            if(current.children[i][2] not in visited):\n",
    "                self.create_matrix_emission(current.children[i][2], visited) \n",
    "        \n",
    "                \n",
    "        self.matrice_emission = self.matrice_emission.fillna(0).astype('float')\n",
    "        self.matrice_emission = self.matrice_emission.reindex(sorted(self.matrice_emission.columns), axis=1)\n",
    "        #self.matrice_emission = self.matrice_emission.to_numpy(dtype = 'float')\n",
    "        \n",
    "    def viterbi_path(self, observations, prior = None, scaled=True, ret_loglik=False):\n",
    "        '''Finds the most-probable (Viterbi) path through the HMM state trellis\n",
    "        Notation:\n",
    "            Z[t] := Observation at time t\n",
    "            Q[t] := Hidden state at time t\n",
    "        Inputs:\n",
    "            prior: np.array(num_hid)\n",
    "                prior[i] := Pr(Q[0] == i)\n",
    "            transmat: np.ndarray((num_hid,num_hid))\n",
    "                transmat[i,j] := Pr(Q[t+1] == j | Q[t] == i)\n",
    "            obslik: np.ndarray((num_hid,num_obs))\n",
    "                obslik[i,t] := Pr(Z[t] | Q[t] == i)\n",
    "            scaled: bool\n",
    "                whether or not to normalize the probability trellis along the way\n",
    "                doing so prevents underflow by repeated multiplications of probabilities\n",
    "            ret_loglik: bool\n",
    "                whether or not to return the log-likelihood of the best path\n",
    "        Outputs:\n",
    "            path: np.array(num_obs)\n",
    "                path[t] := Q[t]\n",
    "        '''\n",
    "        obslik = np.array([self.matrice_emission.to_numpy()[:, z] for z in observations]).T\n",
    "        num_hid = obslik.shape[0] # number of hidden states\n",
    "        num_obs = obslik.shape[1] # number of observations (not observation *states*)\n",
    "        \n",
    "        if not prior:\n",
    "            prior = np.zeros(self.matrice_transition.to_numpy().shape[0])\n",
    "            prior[0] = 1\n",
    "\n",
    "        # trellis_prob[i,t] := Pr((best sequence of length t-1 goes to state i), Z[1:(t+1)])\n",
    "        trellis_prob = np.zeros((num_hid,num_obs))\n",
    "\n",
    "        # trellis_state[i,t] := best predecessor state given that we ended up in state i at t\n",
    "        trellis_state = np.zeros((num_hid,num_obs), dtype=int) # int because its elements will be used as indicies\n",
    "\n",
    "        path = np.zeros(num_obs, dtype=int) # int because its elements will be used as indicies\n",
    "\n",
    "        trellis_prob[:,0] = np.dot(prior, obslik[:,0]) # element-wise mult\n",
    "\n",
    "        if scaled:\n",
    "            scale = np.ones(num_obs) # only instantiated if necessary to save memory\n",
    "            scale[0] = 1.0 / np.sum(trellis_prob[:,0])\n",
    "            trellis_prob[:,0] *= scale[0]\n",
    "\n",
    "        trellis_state[:,0] = 0 # arbitrary value since t == 0 has no predecessor\n",
    "\n",
    "        for t in range(1, num_obs):\n",
    "            for j in range(num_hid):\n",
    "                trans_probs = trellis_prob[:, t - 1] * self.matrice_transition.to_numpy()[:, j] # element-wise mult\n",
    "                trellis_state[j,t] = trans_probs.argmax()\n",
    "                trellis_prob[j,t] = trans_probs[trellis_state[j,t]] # max of trans_probs\n",
    "                trellis_prob[j,t] *= obslik[j,t]\n",
    "            if scaled:\n",
    "                scale[t] = 1.0 / np.sum(trellis_prob[:,t])\n",
    "                trellis_prob[:,t] *= scale[t]\n",
    "\n",
    "        path[-1] = trellis_prob[:,-1].argmax()\n",
    "        for t in range(num_obs-2, -1, -1):\n",
    "            path[t] = trellis_state[(path[t+1]), t+1]\n",
    "\n",
    "        if not ret_loglik:\n",
    "            return path\n",
    "        else:\n",
    "            if scaled:\n",
    "                loglik = -np.sum(np.log(scale))\n",
    "            else:\n",
    "                p = trellis_prob[path[-1], -1]\n",
    "                loglik = p\n",
    "            return path, loglik\n",
    "    \n",
    "    def find_node(self, text, current = None, visited = None):\n",
    "        if not current:\n",
    "            current = self.root\n",
    "            \n",
    "        if not visited:\n",
    "            visited = []\n",
    "        \n",
    "        if current.text == text:\n",
    "            return current\n",
    "        \n",
    "        for child in current.children[1:]:\n",
    "            if(child[2] not in visited):\n",
    "                current = child[2]\n",
    "                visited.append(current)\n",
    "                found = self.find_node(text, current = current, visited = visited)\n",
    "                if found: \n",
    "                    return found\n",
    "    \n",
    "    def prediction(self, seq, L):\n",
    "        S = dict()\n",
    "        path = self.viterbi_path(seq)\n",
    "        current = self.find_node(text = self.matrice_transition.index[path[-1] - 1])\n",
    "        return self.suffixes(current, 1, S, '', L)\n",
    "    \n",
    "    def suffixes(self, current, probability, S, suffix, L):\n",
    "        if L == 0:\n",
    "            return S\n",
    "        \n",
    "        else:\n",
    "            for child in current.children[1:]:\n",
    "                suffix += child[0]\n",
    "                probability = probability * child[1] * child[3]\n",
    "                S[suffix] = probability\n",
    "                found = self.suffixes(child[2], probability, S, suffix, L-1)\n",
    "                if found:\n",
    "                    return found\n",
    "                          \n",
    "    def forward(self, V, a, b, initial_distribution):\n",
    "        alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "        alpha[0, :] = initial_distribution * b[:, V[0] + 1]\n",
    "        #print(alpha)\n",
    "        for t in range(1, V.shape[0]):\n",
    "            for j in range(a.shape[0]):\n",
    "                # Matrix Computation Steps\n",
    "                #                  ((1x2) . (1x2))      *     (1)\n",
    "                #                        (1)            *     (1)\n",
    "                alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t] + 1]\n",
    "            \n",
    "        return alpha\n",
    " \n",
    "    def backward(self, V, a, b):\n",
    "        beta = np.zeros((V.shape[0], a.shape[0]))\n",
    "\n",
    "        # setting beta(T) = 1\n",
    "        beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    "\n",
    "        # Loop in backward way from T-1 to\n",
    "        # Due to python indexing the actual loop will be T-2 to 0\n",
    "        for t in range(V.shape[0] - 2, -1, -1):\n",
    "            for j in range(a.shape[0]):\n",
    "                beta[t, j] = (beta[t + 1] * b[:, V[t + 1] + 1]).dot(a[j, :])\n",
    "        \n",
    "        return beta\n",
    " \n",
    "    def baum_welch(self, obs, initial_distribution = None, n_iter = 100):\n",
    "        \n",
    "        a = self.matrice_transition.to_numpy()\n",
    "        b = self.matrice_emission.to_numpy()\n",
    "        \n",
    "        \n",
    "        if not initial_distribution:\n",
    "            initial_distribution = np.full(self.matrice_transition.to_numpy().shape[0], 1/self.matrice_transition.to_numpy().shape[0])\n",
    "            #initial_distribution[0] = 1\n",
    "        \n",
    "        M = a.shape[0]\n",
    "        T = len(obs)\n",
    "\n",
    "        for n in range(n_iter):\n",
    "            alpha = self.forward(obs, a, b, initial_distribution)\n",
    "            beta = self.backward(obs, a, b)\n",
    "\n",
    "            xi = np.zeros((M, M, T - 1))\n",
    "            for t in range(T - 1):\n",
    "                denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, obs[t + 1] + 1].T, beta[t + 1, :])\n",
    "                for i in range(M):\n",
    "                    numerator = alpha[t, i] * a[i, :] * b[:, obs[t + 1] + 1].T * beta[t + 1, :].T\n",
    "                    xi[i, :, t] = numerator / denominator\n",
    "\n",
    "            gamma = np.sum(xi, axis=1) \n",
    "            a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "            # Add additional T'th element in gamma\n",
    "            gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "            K = b.shape[1]\n",
    "            denominator = np.sum(gamma, axis=1)\n",
    "            for l in range(K):\n",
    "                b[:, l] = np.sum(gamma[:, obs == l + 1], axis=1)\n",
    "\n",
    "            b = np.divide(b, denominator.reshape((-1, 1)))\n",
    "            \n",
    "        tmp1 = self.matrice_transition\n",
    "        tmp2 = self.matrice_emission\n",
    "        \n",
    "        self.matrice_transition = pd.DataFrame(a, index = tmp1.index, columns = tmp1.columns)\n",
    "        self.matrice_emission = pd.DataFrame(b, index = tmp2.index, columns = tmp2.columns)\n",
    "    \n",
    "    def display(self):\n",
    "        '''\n",
    "        Prints the contents of this prefix tree.\n",
    "        '''\n",
    "        print('====================================================================================')\n",
    "        self.__displayHelper(self.root)\n",
    "        print('====================================================================================\\n')\n",
    "    \n",
    "    def __displayHelper(self, current, visited = None):\n",
    "        '''\n",
    "        Private helper for printing the contents of this prefix tree.\n",
    "        '''\n",
    "        if not visited: \n",
    "            visited = []\n",
    "            visited.append(current)\n",
    "        \n",
    "        print(current, \"\\n\")\n",
    "        \n",
    "        for child in current.children[1:]:\n",
    "            if child[2] not in visited:\n",
    "                visited.append(current)\n",
    "                self.__displayHelper(child[2], visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaa', 'aaba', 'ababa', 'bb', 'bbaaa', 'cb']\n"
     ]
    }
   ],
   "source": [
    "seq = ['aaa', 'aaba', 'ababa', 'bb', 'cb', 'bbaaa']\n",
    "seq.sort()\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = PrefixTree()\n",
    "for seqq in seq:\n",
    "    trie.insert(seqq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the DFA with the FPTA:\n",
    "\n",
    "To transform a prefix tree into a frequency automaton (and thus probabilistic), a state-merging algorithm is used. Currently, the best one has been created by Colin de la Higuera. It is implemented from scratch below:\n",
    "\n",
    "First of all, we have in parameters the sequences and an alpha parameter [0, 1]. \n",
    "We create the tree then we initialize 2 lists: red & blue: \n",
    "- Red stores all nodes that have already been defined as representative nodes and will be included in the final output model.\n",
    "- Blue stores nodes that have not yet been tested.\n",
    "\n",
    "The purpose of the algorithm is to keep only the red states. At the beginning,RED contains only the root node, whileBlue contains the immediate successor nodes of the initial node: the child nodes of the root. When executing the external loop of the algorithm, the first qb node in BLUE is chosen. If there is a qr node in RED compatible with qb, then qb and its successor nodes are merged with qr and the corresponding successor nodes of qr, respectively, as described in the Merge&Fold part. If qb is not compatible with any of the states of RED, it will be promoted, i.e. it will switch to RED, and its respective children will switch to BLUE.\n",
    "\n",
    "#### Merge&Fold operation:\n",
    "Given the DFA, the merge operation takes 2 states q and q′, where q is a RED state and q′ is a BLUE state compatible with the Hoeffding test. Merge operation consists of 2 steps. First, if q′est is a final state, then q becomes one as well (if it was not already the case) and the number of sequences ending in q′ is added to the number of sequences ending in q. Second, incoming arcs at q′sont redirected to q. If such arcs already exist, the number of passing sequences in each incoming arc is added to the existing arc. The Fold operation is a recursive function consisting in merging the successor nodes q′ into q and the corresponding successor nodes of q respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Original_Alergia(sequences, alpha):\n",
    "    '''\n",
    "    Original version of the Alergia Algorithm\n",
    "    \n",
    "    Arguments: \n",
    "    sequences -- the sequences to build the Trie and then convert it in a PFA\n",
    "    alpha -- an int between 0 and 1. It represents a parameter of the Hoeffding bounds. \n",
    "    \n",
    "    Return:\n",
    "    A DPA according to the sequences we have\n",
    "    '''\n",
    "    print('Starting building corresponding Trie \\n')\n",
    "    trie = PrefixTree()\n",
    "    trie.alphabet = list({l for word in sequences for l in word})\n",
    "    for subseq in sequences:\n",
    "        trie.insert(subseq)\n",
    "    print(trie.size())\n",
    "    #print(trie.leaf())\n",
    "    #initial = trie.size()\n",
    "    red = []\n",
    "    red.append(trie.root)\n",
    "    blue = []\n",
    "    for x in trie.root.children[1:]:\n",
    "        if(x[2] not in blue):\n",
    "            blue.append(x[2])\n",
    "    t0 = 0.5\n",
    "    \n",
    "    print('Running Alergia on trie \\n')\n",
    "    while(len(blue) > 0):\n",
    "        qb = blue[0]\n",
    "        blue.remove(qb)\n",
    "        promote = True\n",
    "        if(qb.get_frequency() >= t0):\n",
    "            for qr in red:\n",
    "                if(Original_AlergiaCompatible(trie, qr, qb, alpha)):\n",
    "                    #print('Merge accepted...')\n",
    "                    #print(qr)\n",
    "                    #print(qb)\n",
    "                    trie = Original_MergeFold(trie, qr, qb)\n",
    "                    promote = False\n",
    "                    for child in qr.children[1:]:    \n",
    "                        if(child[2] not in blue and child[2].state != qr.state and child[2] not in red):\n",
    "                            blue.append(child[2])\n",
    "                    break\n",
    "        \n",
    "            if(promote == True):\n",
    "                #print('No merge possible...')\n",
    "                red.append(qb)\n",
    "                for child in qb.children[1:]:\n",
    "                    if(child[2] not in blue and child[2] not in red):\n",
    "                        blue.append(child[2])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    trie.transform2proba()\n",
    "    print('Algo done')\n",
    "    return trie\n",
    "\n",
    "def Original_AlergiaCompatible(trie, qr, qb, alpha):\n",
    "    '''\n",
    "    Sub-method of the Alergia main one. It tells us if 2 nodes (a red and a blue) are compatible\n",
    "    \n",
    "    Arguments:\n",
    "    trie -- the current trie we are working on\n",
    "    qr -- a red node \n",
    "    qb -- a blue node\n",
    "    alpha -- parameter alpha mentionned above\n",
    "    \n",
    "    Return:\n",
    "    a boolean saying whether or not the 2 nodes in arguments are compatible\n",
    "    '''\n",
    "    correct = True\n",
    "    if(Original_AlergiaTest(qr.children[0][1], qr.get_frequency(), qb.children[0][1], qb.get_frequency(), alpha) == False):\n",
    "        correct = False\n",
    "    \n",
    "    for a in trie.alphabet:\n",
    "        for children_r in qr.children:\n",
    "            for children_b in qb.children:\n",
    "                if(a == children_r[1] and a == children_b[1]):\n",
    "                    if(Original_AlergiaTest(children_r[2], children_r.get_frequency(), children_b[2], children_b.get_frequency(), alpha) == False):\n",
    "                        correct = False\n",
    "    return correct\n",
    "  \n",
    "def Original_AlergiaTest(f1, n1, f2, n2, alpha):\n",
    "    '''\n",
    "    Sub-method of the Alergia compatible method. It computes the hoeffding bounds and compare it to the gamma threshold\n",
    "    \n",
    "    Arguments:\n",
    "    f1 -- incoming frequency of the node 1\n",
    "    n1 -- number of times a word ends in node 1\n",
    "    f2 -- incoming frequency of the node 2\n",
    "    n2 -- number of times a word ends in node 2\n",
    "    1 & 2 refers to the nodes we want to compare (i.e a node Red and a node Blue)\n",
    "    alpha -- same parameter alpha as mentionned\n",
    "    \n",
    "    Return:\n",
    "    True if gamma < hoeffding (then, the nodes are compatible)\n",
    "    False if not\n",
    "    '''\n",
    "    gamma = math.fabs(f1/n1 - f2/n2)\n",
    "    root = math.sqrt(1/(2*math.log(2/alpha)))\n",
    "    summ = (1/math.sqrt(n1)) + (1/math.sqrt(n2))\n",
    "    hoeffding = root * summ\n",
    "    return gamma < hoeffding\n",
    "\n",
    "def Original_MergeFold(trie, qr, qb): \n",
    "    '''\n",
    "    MERGE OPERATION: \n",
    "    To merge a BLUE node into a RED node, all the ingoing links of BLUE node are redirected to the RED node. \n",
    "    If the RED node already has an ingoing link with the same item attribute as a redirected link, then only the frequencies are added. \n",
    "    Next, the BLUE node attribute is added to the RED node attribute.\n",
    "    \n",
    "    FOLD OPERATION:\n",
    "    When a BLUE node merges into a RED node, all children of BLUE node are recursively merged into children of the RED node with the same item attribute link.\n",
    "    If the link with an item attribute doesn't exist in the RED node, a new child is inserted.\n",
    "    \n",
    "    Arguments:\n",
    "    trie -- the current Trie we are working on\n",
    "    qr -- the red node \n",
    "    qb -- the blue node to merge\n",
    "    '''\n",
    "    q = qb.previous[0]\n",
    "    \n",
    "    if qb.text[-1] not in qr.text:\n",
    "        qr.text = qr.text+ ', ' + qb.text[-1]\n",
    "        \n",
    "    for child in q.children:\n",
    "        if(child[2].state == qb.state):\n",
    "            child[2] = qr \n",
    "            \n",
    "    qr.children[0][1] += qb.children[0][1]\n",
    "    \n",
    "    words = trie.starts_with('', current = qb)\n",
    "    \n",
    "    for word in words:\n",
    "        trie.insert(word)\n",
    "        \n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting building corresponding Trie \n",
      "\n",
      "115\n",
      "Running Alergia on trie \n",
      "\n",
      "Algo done\n",
      "Wall time: 7 ms\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "%time dfa = Original_Alergia(seq2j, 0.5)\n",
    "print(dfa.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.transform_to_HMMT()\n",
    "dfa.create_matrix_transition()\n",
    "dfa.create_matrix_emission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alergia(sequences, alpha):\n",
    "    '''\n",
    "    Our version of the Alergia algorithm. It tries to recursively merge all the pairs of nodes, from the root to the leaves.\n",
    "    Unlike the original version, the difference is that it does not test the compatibility of children of these pairs of nodes.\n",
    "    \n",
    "    Arguments: \n",
    "    sequences -- the sequences to build the Trie and then convert it in a PFA\n",
    "    alpha -- an int between 0 and 1. It represents a parameter of the Hoeffding bounds. \n",
    "    \n",
    "    Return:\n",
    "    A DPA according to the sequences we have\n",
    "    '''\n",
    "    \n",
    "    print('Starting building corresponding Trie \\n')\n",
    "    \n",
    "    trie = PrefixTree()\n",
    "    \n",
    "    trie.alphabet = list({l for word in sequences for l in word})\n",
    "    \n",
    "    for subseq in sequences:\n",
    "        trie.insert(subseq)\n",
    "        \n",
    "    #print(trie.size())\n",
    "    #print(trie.leaf())\n",
    "    #initial = trie.size()\n",
    "    red = []\n",
    "    \n",
    "    red.append(trie.root)\n",
    "    \n",
    "    blue = []\n",
    "    \n",
    "    for x in trie.root.children[1:]:\n",
    "        if(x[2] not in blue):\n",
    "            blue.append(x[2])\n",
    "            \n",
    "    t0 = 0.5\n",
    "    \n",
    "    print('Running Alergia on trie \\n')\n",
    "    \n",
    "    while(len(blue) > 0):\n",
    "        qb = blue[0]\n",
    "        blue.remove(qb)\n",
    "        promote = True\n",
    "        if(qb.get_frequency() >= t0):\n",
    "            for qr in red:\n",
    "                if(AlergiaCompatible(trie, qr, qb, alpha)):\n",
    "                    #print('Merge accepted...')\n",
    "                    #print(qr)\n",
    "                    #print(qb)\n",
    "                    trie = MergeFold(trie, qr, qb)\n",
    "                    promote = False\n",
    "                    for child in qr.children[1:]:    \n",
    "                        if(child[2] not in blue and child[2].state != qr.state and child[2] not in red):\n",
    "                            blue.append(child[2])\n",
    "                    break\n",
    "        \n",
    "            if(promote == True):\n",
    "                #print('No merge possible...')\n",
    "                red.append(qb)\n",
    "                for child in qb.children[1:]:\n",
    "                    if(child[2] not in blue and child[2] not in red):\n",
    "                        blue.append(child[2])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    trie.transform2proba()\n",
    "    print('Algo done')\n",
    "    return trie\n",
    "\n",
    "def AlergiaCompatible(trie, qr, qb, alpha):\n",
    "    '''\n",
    "    Sub-method of the Alergia main one. It tells us if 2 nodes (a red and a blue) are compatible\n",
    "    \n",
    "    Arguments:\n",
    "    trie -- the current trie we are working on\n",
    "    qr -- a red node \n",
    "    qb -- a blue node\n",
    "    alpha -- parameter alpha mentionned above\n",
    "    \n",
    "    Return:\n",
    "    a boolean saying whether or not the 2 nodes in arguments are compatible\n",
    "    '''\n",
    "    correct = True\n",
    "    \n",
    "    if(AlergiaTest(qr.children[0][1], qr.get_frequency(), qb.children[0][1], qb.get_frequency(), alpha) == False):\n",
    "        correct = False\n",
    "    \n",
    "    return correct\n",
    "  \n",
    "def AlergiaTest(f1, n1, f2, n2, alpha):\n",
    "    '''\n",
    "    Sub-method of the Alergia compatible method. It computes the hoeffding bounds and compare it to the gamma threshold\n",
    "    \n",
    "    Arguments:\n",
    "    f1 -- incoming frequency of the node 1\n",
    "    n1 -- number of times a word ends in node 1\n",
    "    f2 -- incoming frequency of the node 2\n",
    "    n2 -- number of times a word ends in node 2\n",
    "    1 & 2 refers to the nodes we want to compare (i.e a node Red and a node Blue)\n",
    "    alpha -- same parameter alpha as mentionned\n",
    "    \n",
    "    Return:\n",
    "    True if gamma < hoeffding (then, the nodes are compatible)\n",
    "    False if not\n",
    "    '''\n",
    "    gamma = math.fabs(f1/n1 - f2/n2)\n",
    "    root = math.sqrt(1/(2*math.log(2/alpha)))\n",
    "    summ = (1/math.sqrt(n1)) + (1/math.sqrt(n2))\n",
    "    hoeffding = root * summ\n",
    "    return gamma < hoeffding\n",
    "\n",
    "def MergeFold(trie, qr, qb): \n",
    "    '''\n",
    "    MERGE OPERATION: \n",
    "    To merge a BLUE node into a RED node, all the ingoing links of BLUE node are redirected to the RED node. \n",
    "    If the RED node already has an ingoing link with the same item attribute as a redirected link, then only the frequencies are added. \n",
    "    Next, the BLUE node attribute is added to the RED node attribute.\n",
    "    \n",
    "    FOLD OPERATION:\n",
    "    When a BLUE node merges into a RED node, all children of BLUE node are recursively merged into children of the RED node with the same item attribute link.\n",
    "    If the link with an item attribute doesn't exist in the RED node, a new child is inserted.\n",
    "    \n",
    "    Arguments:\n",
    "    trie -- the current Trie we are working on\n",
    "    qr -- the red node \n",
    "    qb -- the blue node to merge\n",
    "    '''\n",
    "    q = qb.previous[0]\n",
    "    \n",
    "    if qb.text[-1] not in qr.text:\n",
    "        qr.text = qr.text+ ', ' + qb.text[-1]\n",
    "        \n",
    "    for child in q.children:\n",
    "        if(child[2].state == qb.state):\n",
    "            child[2] = qr \n",
    "            \n",
    "    qr.children[0][1] += qb.children[0][1]\n",
    "    \n",
    "    words = trie.starts_with('', current = qb)\n",
    "    \n",
    "    for word in words:\n",
    "        trie.insert(word)\n",
    "        \n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting building corresponding Trie \n",
      "\n",
      "Running Alergia on trie \n",
      "\n",
      "Algo done\n",
      "Wall time: 5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 1426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dfa_2 = Alergia(seq2j, 1/125)\n",
    "dfa_2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_2.transform_to_HMMT()\n",
    "dfa_2.create_matrix_transition()\n",
    "dfa_2.create_matrix_emission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "symb:λ, 9, 1, 7, 8, 3, 0 state:134 -> children:[['#', 0.07738095238095238, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['9', 0.0744047619047619, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['1', 0.11309523809523808, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['7', 0.05654761904761904, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['8', 0.33035714285714285, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['3', 0.10416666666666667, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['0', 0.244047619047619, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.6086956521739131], ['2', 0.24550898203592814, <__main__.TrieNode object at 0x0000023F60A5B508>, 0.302536231884058], ['4', 0.46107784431137727, <__main__.TrieNode object at 0x0000023F60A5B508>, 0.302536231884058], ['6', 0.2934131736526946, <__main__.TrieNode object at 0x0000023F60A5B508>, 0.302536231884058], ['5', 1.0, <__main__.TrieNode object at 0x0000023F626B0708>, 0.08876811594202899]] \n",
      "\n",
      "symb:2, 4, 6 state:157 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F60A5B508>, 0.28205128205128205], ['7', 1.0, <__main__.TrieNode object at 0x0000023F99631848>, 0.02564102564102564], ['0', 1.0, <__main__.TrieNode object at 0x0000023F4F62AD08>, 0.14102564102564102], ['1', 1.0, <__main__.TrieNode object at 0x0000023F8ABCECC8>, 0.08974358974358974], ['6', 1.0, <__main__.TrieNode object at 0x0000023FAF77CC88>, 0.07692307692307693], ['8', 1.0, <__main__.TrieNode object at 0x0000023F29FCC2C8>, 0.16666666666666666], ['5', 1.0, <__main__.TrieNode object at 0x0000023F9E7B8208>, 0.07692307692307693], ['3', 1.0, <__main__.TrieNode object at 0x0000023F8D4AFB08>, 0.05128205128205128], ['9', 1.0, <__main__.TrieNode object at 0x0000023F9DA76208>, 0.05128205128205128], ['2', 1.0, <__main__.TrieNode object at 0x0000023F8DCFC8C8>, 0.02564102564102564], ['4', 1.0, <__main__.TrieNode object at 0x0000023F626AAD48>, 0.01282051282051282]] \n",
      "\n",
      "symb:27 state:158 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F99631848>, 1.0]] \n",
      "\n",
      "symb:20 state:165 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F4F62AD08>, 0.9090909090909091], ['5', 1.0, <__main__.TrieNode object at 0x0000023F4F621D48>, 0.09090909090909091]] \n",
      "\n",
      "symb:605 state:254 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F4F621D48>, 1.0]] \n",
      "\n",
      "symb:21 state:180 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8ABCECC8>, 1.0]] \n",
      "\n",
      "symb:26, 9 state:181 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023FAF77CC88>, 0.7], ['8', 1.0, <__main__.TrieNode object at 0x0000023F8D4AF908>, 0.1], ['5', 1.0, <__main__.TrieNode object at 0x0000023F72766988>, 0.1], ['6', 1.0, <__main__.TrieNode object at 0x0000023F9E9E3888>, 0.1]] \n",
      "\n",
      "symb:268 state:225 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8D4AF908>, 1.0]] \n",
      "\n",
      "symb:465 state:251 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F72766988>, 1.0]] \n",
      "\n",
      "symb:596 state:255 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F9E9E3888>, 1.0]] \n",
      "\n",
      "symb:28 state:184 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F29FCC2C8>, 0.9230769230769231], ['3', 1.0, <__main__.TrieNode object at 0x0000023F8D60A788>, 0.07692307692307693]] \n",
      "\n",
      "symb:483 state:250 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8D60A788>, 1.0]] \n",
      "\n",
      "symb:25 state:190 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F9E7B8208>, 1.0]] \n",
      "\n",
      "symb:23 state:223 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8D4AFB08>, 1.0]] \n",
      "\n",
      "symb:29 state:229 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F9DA76208>, 1.0]] \n",
      "\n",
      "symb:42 state:252 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8DCFC8C8>, 1.0]] \n",
      "\n",
      "symb:64 state:253 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F626AAD48>, 1.0]] \n",
      "\n",
      "symb:5 state:169 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F626B0708>, 0.10204081632653061], ['6', 1.0, <__main__.TrieNode object at 0x0000023F8DA4D1C8>, 0.08163265306122448], ['0', 1.0, <__main__.TrieNode object at 0x0000023F8ABCE408>, 0.12244897959183673], ['2', 1.0, <__main__.TrieNode object at 0x0000023FA4940048>, 0.08163265306122448], ['8', 1.0, <__main__.TrieNode object at 0x0000023F60A5AA08>, 0.32653061224489793], ['9', 1.0, <__main__.TrieNode object at 0x0000023FAF77CC88>, 0.10204081632653061], ['3', 1.0, <__main__.TrieNode object at 0x0000023F70C27EC8>, 0.10204081632653061], ['4', 1.0, <__main__.TrieNode object at 0x0000023F812DD708>, 0.061224489795918366], ['1', 1.0, <__main__.TrieNode object at 0x0000023F92501648>, 0.02040816326530612]] \n",
      "\n",
      "symb:56 state:170 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8DA4D1C8>, 1.0]] \n",
      "\n",
      "symb:50 state:179 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F8ABCE408>, 0.8333333333333334], ['4', 1.0, <__main__.TrieNode object at 0x0000023F815B9848>, 0.16666666666666666]] \n",
      "\n",
      "symb:504 state:242 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F815B9848>, 1.0]] \n",
      "\n",
      "symb:52 state:182 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023FA4940048>, 1.0]] \n",
      "\n",
      "symb:58 state:185 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F60A5AA08>, 0.8125], ['0', 1.0, <__main__.TrieNode object at 0x0000023F815B9488>, 0.0625], ['2', 1.0, <__main__.TrieNode object at 0x0000023F906D4BC8>, 0.0625], ['3', 1.0, <__main__.TrieNode object at 0x0000023F80EE9448>, 0.0625]] \n",
      "\n",
      "symb:580 state:186 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F815B9488>, 1.0]] \n",
      "\n",
      "symb:582 state:238 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F906D4BC8>, 1.0]] \n",
      "\n",
      "symb:1583 state:249 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F80EE9448>, 1.0]] \n",
      "\n",
      "symb:53 state:202 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F70C27EC8>, 0.6], ['8', 1.0, <__main__.TrieNode object at 0x0000023FA49341C8>, 0.4]] \n",
      "\n",
      "symb:54 state:220 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F812DD708>, 1.0]] \n",
      "\n",
      "symb:51 state:241 -> children:[['#', 1.0, <__main__.TrieNode object at 0x0000023F92501648>, 1.0]] \n",
      "\n",
      "====================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfa_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9': 0.04528985507246377}\n"
     ]
    }
   ],
   "source": [
    "s = dfa_2.prediction(np.array([4, 4, 2, 5]), 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9': 0.0444104134762634}\n"
     ]
    }
   ],
   "source": [
    "s = dfa.prediction(np.array([4, 4, 2, 5]), 1)\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
